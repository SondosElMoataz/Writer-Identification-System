{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\farah\\anaconda3\\lib\\site-packages (3.4.2.17)\nRequirement already satisfied: numpy>=1.14.5 in c:\\users\\farah\\anaconda3\\lib\\site-packages (from opencv-python) (1.19.5)\nNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "#import matplotlib.pyplot as plt\n",
    "from skimage.exposure import histogram\n",
    "#from matplotlib.pyplot import bar\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage import io ,filters\n",
    "from sklearn.svm import SVC\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,titles=None):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        plt.axis('off')\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess(image):\n",
    "     \n",
    "    # Remove salt and pepper noise    \n",
    "    # Remove noise \n",
    "    median = cv2.medianBlur(image,5)\n",
    "    blur = cv2.GaussianBlur(image,(5,5),0)\n",
    "   \n",
    "    greyImg = image\n",
    "    \n",
    "    # Otsu's Binarization\n",
    "    ret3,img = cv2.threshold(image,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "   \n",
    "    # Remove header and footer\n",
    "    length, width = img.shape\n",
    "    up, down, left, right = 0, length - 1, 0, width - 1\n",
    "\n",
    "    minWidthOfLines = width/2\n",
    "    contours,__ = cv2.findContours(img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for i in contours:\n",
    "        x, y, w, h = cv2.boundingRect(i)\n",
    "        if w < minWidthOfLines:\n",
    "            continue\n",
    "        if y < length // 2:\n",
    "            up = max(up, y + 15)\n",
    "        else:\n",
    "            down = min(down, y - 15)\n",
    "\n",
    "    offset = 30\n",
    "    left = left + offset\n",
    "    right = right -offset\n",
    "    noHeaderAndFooter = img[up:down + 1, left:right + 1]\n",
    "    noHeaderAndFooter = np.asarray(noHeaderAndFooter)\n",
    "    \n",
    "    noHeaderAndFooterGrey = greyImg[up:down + 1, left:right + 1]\n",
    "    noHeaderAndFooterGrey = np.asarray(noHeaderAndFooterGrey) \n",
    "   \n",
    "    # To crop the image\n",
    "    row, col = noHeaderAndFooter.shape\n",
    "    tolerance = 5\n",
    "\n",
    "    sumOfRows = np.sum(noHeaderAndFooter, axis = 1)\n",
    "    rowIndices = np.where(sumOfRows< (col-tolerance)*255)\n",
    "    up = np.min(rowIndices)\n",
    "    down = np.max(rowIndices)\n",
    "\n",
    "    sumOfColoumns = np.sum(noHeaderAndFooter, axis = 0)\n",
    "    colIndices = np.where(sumOfColoumns< (row-tolerance)*255)\n",
    "    left = np.min(colIndices)\n",
    "    right = np.max(colIndices)\n",
    "\n",
    "    binarized = noHeaderAndFooter[up:down + 1, left:right + 1]\n",
    "    binarized = np.asarray(binarized)\n",
    "    \n",
    "    greyscale = noHeaderAndFooterGrey[up:down + 1, left:right + 1]\n",
    "    greyscale = np.asarray(greyscale)\n",
    "   \n",
    "    # Segmentation of Lines\n",
    "    rowIndicesShifted = np.roll(rowIndices, -1)\n",
    "    rowIndicesShifted = rowIndicesShifted[0]\n",
    "\n",
    "    transitionIndices = np.where(np.abs(rowIndices - rowIndicesShifted) > 10)\n",
    "    transitionIndices = transitionIndices[1]\n",
    "\n",
    "    rowIndices = rowIndices[0]\n",
    "\n",
    "    downIndices= rowIndices[transitionIndices]\n",
    "\n",
    "    transitionIndicesUp = np.insert(transitionIndices,0,-1)\n",
    "    transitionIndicesUp = np.delete(transitionIndicesUp,-1)\n",
    "\n",
    "    upIndices= rowIndices[transitionIndicesUp+1]\n",
    "    \n",
    "    segmentsBinarized = []\n",
    "    segmentsGrey = []\n",
    "    totalSize=0\n",
    "    whiteSpaceTolerance=0.975\n",
    "    for i in range(transitionIndices.shape[0]):\n",
    "        currSegment= noHeaderAndFooterGrey[upIndices[i]:downIndices[i] + 1, left:right + 1]\n",
    "        if((np.sum(currSegment))<(currSegment.shape[0]*currSegment.shape[1]*whiteSpaceTolerance*255)):\n",
    "            segmentsBinarized.append(noHeaderAndFooter[upIndices[i]:downIndices[i] + 1, left:right + 1])\n",
    "            segmentsGrey.append(currSegment)\n",
    "          \n",
    "    segmentsGrey=np.asarray(segmentsGrey)\n",
    "    \n",
    "    return greyscale, binarized, segmentsBinarized, segmentsGrey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showHist(imgHist):\n",
    "    bar(imgHist[1].astype(np.uint8), imgHist[0], width=0.8, align='center')\n",
    "    return imgHist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Feature Extraction LBP\n",
    "def LBP(greyscale):\n",
    "    lbp = local_binary_pattern(greyscale, 8, 3, method='uniform')\n",
    "    n_bins =10 #256 \n",
    "    imgHist = histogram(lbp, n_bins)\n",
    "    \n",
    "    return imgHist[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(greyscale1, binarized1, segmentsBinarized1, segmentsGrey1):\n",
    "    return LBP(segmentsGrey1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(folder):\n",
    "    trainTime=0\n",
    "    feature_vector_all=[]\n",
    "    direcs = glob.glob (folder+\"/*\")\n",
    "    for direc in direcs:\n",
    "        if os.path.isdir(direc):\n",
    "            print(direc)\n",
    "            files = glob.glob (direc+'/*')\n",
    "            for file in files:\n",
    "                #reading an imag\n",
    "                print(\"-----------------------\",file,\"------------------------------\")\n",
    "                img = cv2.imread(file,0) \n",
    "                tempStart =time.time()\n",
    "\n",
    "                #converting it to a gray image\n",
    "                #binarization process\n",
    "                \n",
    "                greyscale1, binarized1, segmentsBinarized1, segmentsGrey1 = Preprocess(img)\n",
    "                print(segmentsGrey1.shape)\n",
    "                for i in range(segmentsGrey1.shape[0]):\n",
    "                    feature_vector=[]\n",
    "                    \n",
    "                    feature_vector.append(int(direc[8]))\n",
    "                    \n",
    "                    hist1 = extract_features(greyscale1, binarized1, segmentsBinarized1, segmentsGrey1[i])\n",
    "                    feature_vector.extend(hist1)\n",
    "                    feature_vector_all.append(feature_vector)\n",
    "                tempEnd =time.time()\n",
    "                trainTime+= tempEnd-tempStart \n",
    "\n",
    "    return feature_vector_all,trainTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDistance(x1, x2):\n",
    "\n",
    "    distance =np.linalg.norm(x1-x2)\n",
    "    return distance\n",
    "\n",
    "# def KNN(test_point, training_features, labels, k): \n",
    "#     y= labels[ np.argsort(calculateDistance(test_point,training_features))[:k]]\n",
    "#     l,h = np.unique(y, return_counts=True)\n",
    "#     return l[np.argmax(h)]\n",
    "\n",
    "#     distarr=[]\n",
    "#     for i in range (training_features.shape[0]):\n",
    "#         f=calculateDistance(training_features[i,:],test_point)\n",
    "#         distarr.append(f)\n",
    "        \n",
    "        \n",
    "#     sortedarr=np.sort(distarr)\n",
    "    \n",
    "#     classes=np.zeros(3)\n",
    "    \n",
    "#     for i in range(k):\n",
    "#         result = np.where(distarr == sortedarr[i])\n",
    "#         print(result)\n",
    "#         for j in range(3):\n",
    "#             if(labels[result[0]]==j+1):\n",
    "#                 classes[j]+=1\n",
    "            \n",
    "            \n",
    "#     classification=np.argmax(classes)\n",
    "\n",
    "  \n",
    "#     return classification+1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(test_point, training_features, y_train, k):\n",
    "    class1=0\n",
    "    class2=0\n",
    "    class3=0\n",
    "    dist=[]\n",
    "    indexs=[]\n",
    "    \n",
    "    for i in range(training_features.shape[0]):\n",
    "        dist.append(calculateDistance(test_point,training_features[i]))\n",
    "        \n",
    "    dist2=np.argsort(dist)\n",
    "\n",
    "    for i in range(k):\n",
    "        if(y_train[dist2[i]]==1):\n",
    "            class1=class1+1\n",
    "        elif(y_train[dist2[i]]==2):\n",
    "            class2=class2+1\n",
    "        else:\n",
    "            class3=class3+1\n",
    "\n",
    "    if(max(class1,class2,class3)==class1):\n",
    "        classification=1\n",
    "    elif(max(class1,class2,class3)==class2):\n",
    "        classification=2\n",
    "    else:\n",
    "        classification=3\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(training_features, y_train):\n",
    "    clf = SVC(kernel='poly')    #linear sigmoid\n",
    "    clf.fit(training_features, y_train)  \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(directory,true_values,l):\n",
    "    training_data,trainTime = train(directory)\n",
    "\n",
    "    training_data = np.asarray(training_data)\n",
    "\n",
    "    labels = training_data[:,0]\n",
    "    training_features = training_data[:,1:]\n",
    "    test_images = sorted(glob.glob(directory+'/*.png'))\n",
    "\n",
    "    ids = open('ids.txt')\n",
    "    ids = ids.readlines()\n",
    "    ids=np.asarray(ids,dtype=int)\n",
    "    xtest=ids[-1]\n",
    "    ytest=np.where(ids==xtest)[0][0]+1\n",
    "    #print(ytest)\n",
    "    \n",
    "    true_values.append(ytest)\n",
    "    print(true_values[l])\n",
    "\n",
    "    #true_values = int(str(os.path.basename(test_images[0])).split(\".\")[0])\n",
    "    k = 5\n",
    "    knn_prediction = []\n",
    "    SVM_prediction=[]\n",
    "    totalTime=[]\n",
    "\n",
    "    f = open(\"time.txt\", \"a\")\n",
    "    f2= open(\"results.txt\",\"a\")\n",
    "    clf= SVM(training_features,labels)\n",
    "\n",
    "    for i in range(len(test_images)):\n",
    "    \n",
    "        img_original = cv2.imread(test_images[i],0)\n",
    "        start = time.time()\n",
    "        greyscale1, binarized1, segmentsBinarized1, segmentsGrey1 = Preprocess(img_original)\n",
    "        maxOccurSegment=[]\n",
    "        maxOccurSegmentSVM=[]\n",
    "        print(\"Actual class :\", true_values, \" of file \", test_images[i])\n",
    "        print(\"---------------------------------------\")\n",
    "        for j in range(segmentsGrey1.shape[0]):\n",
    "            test_point = extract_features(greyscale1, binarized1, segmentsBinarized1, segmentsGrey1[j])\n",
    "\n",
    "            maxOccurSegment.append(KNN(test_point, training_features, labels, k))\n",
    "            maxOccurSegmentSVM.append(clf.predict([test_point])[0])  #SVM\n",
    "\n",
    "\n",
    "        maxOccurSegment=np.asarray(maxOccurSegment)\n",
    "        maxOccurSegmentSVM=np.asarray(maxOccurSegmentSVM)\n",
    "\n",
    "        print(maxOccurSegmentSVM)\n",
    "        knn_prediction.append(np.bincount(maxOccurSegment).argmax())\n",
    "        SVM_prediction.append(np.bincount(maxOccurSegmentSVM).argmax())\n",
    "        end = time.time()\n",
    "        predictionTime= end-start\n",
    "        totalTime.append(trainTime+ predictionTime)\n",
    "\n",
    "        f.write(str(round(totalTime[i],2)))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        f2.write(str(knn_prediction[i]))\n",
    "        f2.write(\"\\n\")\n",
    "\n",
    "\n",
    "        \n",
    "        print(\"knn_prediction class :\", knn_prediction[i])\n",
    "        print(\"SVM_prediction class :\", SVM_prediction[i])\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    f.write(\"------------------------------------\")\n",
    "    totalTime=np.asarray(totalTime)\n",
    "    f.write(str(np.mean(totalTime)))\n",
    "    f.close()\n",
    "    f2.close()\n",
    "\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data\\00\\1\n----------------------- data\\00\\1\\b06-042.png ------------------------------\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-a60bfaa67756>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mknn_predict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSVM_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrue_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mknn_prediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn_predict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mSVM_prediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSVM_predict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-e554a8cd16a4>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(directory, true_values, l)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrue_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtraining_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-ca07da11e436>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(folder)\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[1;31m#binarization process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                 \u001b[0mgreyscale1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarized1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msegmentsBinarized1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msegmentsGrey1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegmentsGrey1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegmentsGrey1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-27dbe069b1d8>\u001b[0m in \u001b[0;36mPreprocess\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mminWidthOfLines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETR_LIST\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHAIN_APPROX_SIMPLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "direcs = glob.glob (\"data/*\")\n",
    "true_values = []\n",
    "knn_prediction = []\n",
    "SVM_prediction=[]\n",
    "\n",
    "for l in range(len(direcs)):\n",
    "    knn_predict, SVM_predict = main(direcs[l],true_values,l)\n",
    "    knn_prediction.append(knn_predict[0])\n",
    "    SVM_prediction.append(SVM_predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "K-Nearest Neighbour Classifier Accuracy:  100.0 %\nSVM Classifier Accuracy:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "total_predictions =  len(direcs)\n",
    "\n",
    "correct_knn=0\n",
    "correct_SVM=0\n",
    "for i in range(total_predictions):\n",
    "    if(true_values[i]==knn_prediction[i]):\n",
    "        correct_knn=correct_knn+1\n",
    "    if(true_values[i]==SVM_prediction[i]):\n",
    "        correct_SVM=correct_SVM+1\n",
    "\n",
    "accuracy_knn = (correct_knn/total_predictions)*100\n",
    "accuracy_SVM = (correct_SVM/total_predictions)*100\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "\n",
    "print(\"K-Nearest Neighbour Classifier Accuracy: \", accuracy_knn, \"%\")\n",
    "print(\"SVM Classifier Accuracy: \", accuracy_SVM, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}