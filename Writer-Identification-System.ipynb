{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\nadin\\anaconda3\\lib\\site-packages (4.5.1.48)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\nadin\\anaconda3\\lib\\site-packages (from opencv-python) (1.19.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.exposure import histogram\n",
    "from matplotlib.pyplot import bar\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage import io ,filters\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,titles=None):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        plt.axis('off')\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess(image):\n",
    "    \n",
    "    # Reading Images\n",
    "#     img = cv2.imread(filename,0) \n",
    "\n",
    "    \n",
    "    # Remove salt and pepper noise    \n",
    "    # Remove noise \n",
    "    median = cv2.medianBlur(image,5)\n",
    "    blur = cv2.GaussianBlur(image,(5,5),0)\n",
    "   \n",
    "    greyImg = image\n",
    "    \n",
    "    # Otsu's Binarization\n",
    "    ret3,img = cv2.threshold(image,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "   \n",
    "    # Remove header and footer\n",
    "    length, width = img.shape\n",
    "    up, down, left, right = 0, length - 1, 0, width - 1\n",
    "\n",
    "    minWidthOfLines = width/2\n",
    "    contours,__ = cv2.findContours(img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for i in contours:\n",
    "        x, y, w, h = cv2.boundingRect(i)\n",
    "        if w < minWidthOfLines:\n",
    "            continue\n",
    "        if y < length // 2:\n",
    "            up = max(up, y + 15)\n",
    "        else:\n",
    "            down = min(down, y - 15)\n",
    "\n",
    "    offset = 30\n",
    "    left = left + offset\n",
    "    right = right -offset\n",
    "    noHeaderAndFooter = img[up:down + 1, left:right + 1]\n",
    "    noHeaderAndFooter = np.asarray(noHeaderAndFooter)\n",
    "    \n",
    "    noHeaderAndFooterGrey = greyImg[up:down + 1, left:right + 1]\n",
    "    noHeaderAndFooterGrey = np.asarray(noHeaderAndFooterGrey) \n",
    "   \n",
    "    # To crop the image\n",
    "    row, col = noHeaderAndFooter.shape\n",
    "    tolerance = 5\n",
    "\n",
    "    sumOfRows = np.sum(noHeaderAndFooter, axis = 1)\n",
    "    rowIndices = np.where(sumOfRows< (col-tolerance)*255)\n",
    "    up = np.min(rowIndices)\n",
    "    down = np.max(rowIndices)\n",
    "\n",
    "    sumOfColoumns = np.sum(noHeaderAndFooter, axis = 0)\n",
    "    colIndices = np.where(sumOfColoumns< (row-tolerance)*255)\n",
    "    left = np.min(colIndices)\n",
    "    right = np.max(colIndices)\n",
    "\n",
    "    binarized = noHeaderAndFooter[up:down + 1, left:right + 1]\n",
    "    binarized = np.asarray(binarized)\n",
    "    \n",
    "    greyscale = noHeaderAndFooterGrey[up:down + 1, left:right + 1]\n",
    "    greyscale = np.asarray(greyscale)\n",
    "   \n",
    "    # Segmentation of Lines\n",
    "    rowIndicesShifted = np.roll(rowIndices, -1)\n",
    "    rowIndicesShifted = rowIndicesShifted[0]\n",
    "\n",
    "    transitionIndices = np.where(np.abs(rowIndices - rowIndicesShifted) > 10)\n",
    "    transitionIndices = transitionIndices[1]\n",
    "\n",
    "    rowIndices = rowIndices[0]\n",
    "\n",
    "    downIndices= rowIndices[transitionIndices]\n",
    "\n",
    "    transitionIndicesUp = np.insert(transitionIndices,0,-1)\n",
    "    transitionIndicesUp = np.delete(transitionIndicesUp,-1)\n",
    "\n",
    "    upIndices= rowIndices[transitionIndicesUp+1]\n",
    "    \n",
    "    segmentsBinarized = []\n",
    "    segmentsGrey = []\n",
    "    for i in range(transitionIndices.shape[0]):\n",
    "        segmentsBinarized.append(noHeaderAndFooter[upIndices[i]:downIndices[i] + 1, left:right + 1])\n",
    "        segmentsGrey.append(noHeaderAndFooterGrey[upIndices[i]:downIndices[i] + 1, left:right + 1])   \n",
    "    \n",
    "#     show_images([greyscale,binarized])\n",
    "#     show_images(segmentsBinarized)\n",
    "#     show_images(segmentsGrey)\n",
    "    \n",
    "    return greyscale, binarized, segmentsBinarized, segmentsGrey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showHist(imgHist):\n",
    "#     plt.figure()\n",
    "#     n_bins = int(img.max() + 1)\n",
    "#     imgHist = histogram(img, n_bins)\n",
    "#     print(imgHist[0])\n",
    "    bar(imgHist[1].astype(np.uint8), imgHist[0], width=0.8, align='center')\n",
    "    return imgHist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Feature Extraction LBP\n",
    "def LBP(greyscale):\n",
    "    lbp = local_binary_pattern(greyscale, 8, 3, method='uniform')\n",
    "#     plt.figure()\n",
    "#     plt.imshow(lbp)\n",
    "    n_bins = int(lbp.max() + 1)\n",
    "    imgHist = histogram(lbp, n_bins)\n",
    "#     hist = showHist(imgHist)\n",
    "    \n",
    "    return imgHist[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(greyscale1, binarized1, segmentsBinarized1, segmentsGrey1):\n",
    "    return LBP(greyscale1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(folder):\n",
    "    feature_vector_all=[]\n",
    "    direcs = glob.glob (folder+\"/*\")\n",
    "    for direc in direcs:\n",
    "        if os.path.isdir(direc):\n",
    "            print(direc)\n",
    "            files = glob.glob (direc+'/*')\n",
    "            for file in files:\n",
    "                #reading an imag\n",
    "                print(\"-----------------------\",file,\"------------------------------\")\n",
    "                img = cv2.imread(file,0) \n",
    "\n",
    "                #converting it to a gray image\n",
    "                #binarization process\n",
    "                greyscale1, binarized1, segmentsBinarized1, segmentsGrey1 = Preprocess(img)\n",
    "\n",
    "                feature_vector=[]\n",
    "                feature_vector.append(int(direc[8]))\n",
    "                \n",
    "                hist1 = extract_features(greyscale1, binarized1, segmentsBinarized1, segmentsGrey1)\n",
    "\n",
    "#                 hist1 = LBP(greyscale1)\n",
    "                feature_vector.extend(hist1)\n",
    "                feature_vector_all.append(feature_vector)\n",
    "\n",
    "\n",
    "    # opening the csv file in 'w+' mode \n",
    "    file = open('dataset.csv', 'w+', newline ='') \n",
    "\n",
    "    # writing the data into the file \n",
    "    with file:\n",
    "            write = csv.writer(file) \n",
    "            write.writerows(feature_vector_all) \n",
    "\n",
    "    return feature_vector_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDistance(x1, x2):\n",
    "\n",
    "    distance =np.linalg.norm(x1-x2)\n",
    "    return distance\n",
    "\n",
    "# def KNN(test_point, training_features, labels, k): \n",
    "#     y= labels[ np.argsort(calculateDistance(test_point,training_features))[:k]]\n",
    "#     l,h = np.unique(y, return_counts=True)\n",
    "#     return l[np.argmax(h)]\n",
    "\n",
    "#     distarr=[]\n",
    "#     for i in range (training_features.shape[0]):\n",
    "#         f=calculateDistance(training_features[i,:],test_point)\n",
    "#         distarr.append(f)\n",
    "        \n",
    "        \n",
    "#     sortedarr=np.sort(distarr)\n",
    "    \n",
    "#     classes=np.zeros(3)\n",
    "    \n",
    "#     for i in range(k):\n",
    "#         result = np.where(distarr == sortedarr[i])\n",
    "#         print(result)\n",
    "#         for j in range(3):\n",
    "#             if(labels[result[0]]==j+1):\n",
    "#                 classes[j]+=1\n",
    "            \n",
    "            \n",
    "#     classification=np.argmax(classes)\n",
    "\n",
    "  \n",
    "#     return classification+1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(test_point, training_features, y_train, k):\n",
    "   \n",
    "    class1=0\n",
    "    class2=0\n",
    "    class3=0\n",
    "    dist=[]\n",
    "    indexs=[]\n",
    "    print(test_point.shape)\n",
    "    print(training_features[0].shape)\n",
    "    \n",
    "    for i in range(6):\n",
    "        dist.append(calculateDistance(test_point,training_features[i]))\n",
    "        \n",
    "    dist2=np.argsort(dist)\n",
    "\n",
    " \n",
    "    for i in range(k):\n",
    "        if(y_train[dist2[i]]==1):\n",
    "            class1=class1+1\n",
    "        elif(y_train[dist2[i]]==2):\n",
    "            class2=class2+1\n",
    "        else:\n",
    "            class3=class3+1\n",
    "\n",
    "    if(max(class1,class2,class3)==class1):\n",
    "        classification=1\n",
    "    elif(max(class1,class2,class3)==class2):\n",
    "        classification=2\n",
    "    else:\n",
    "        classification=3\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    " \n",
    "    data = np.genfromtxt(file_name, delimiter=',')\n",
    "    return data\n",
    "\n",
    "def get_feature_vector(img):\n",
    "    feature_vector=[]\n",
    "   \n",
    "    feature_vector.append()\n",
    "   \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-955f7b9cfa03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mtraining_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mtraining_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "\n",
    "# img_original = cv2.imread('01/1/a01-000u.png')\n",
    "# show_images([img_original])\n",
    "# print(img.max())\n",
    "\n",
    "\n",
    "training_data = train(\"data/01\")\n",
    "# print(training_data)\n",
    "# training_data = read_data('dataset.csv')\n",
    "\n",
    "training_data = np.asarray(training_data)\n",
    "\n",
    "labels = training_data[:,0]\n",
    "training_features = training_data[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_images = sorted(glob.glob('01/*.png'))\n",
    "true_values = [1, 1, 1, 1, 2, 2, 3, 3, 3, 3, 3]\n",
    "k = 1\n",
    "knn_prediction = []\n",
    "\n",
    "for i in range(len(test_images)):\n",
    "   \n",
    "    img_original = cv2.imread(test_images[i],0)\n",
    "    greyscale1, binarized1, segmentsBinarized1, segmentsGrey1 = Preprocess(img_original)\n",
    "    test_point = extract_features(greyscale1, binarized1, segmentsBinarized1, segmentsGrey1)\n",
    "    \n",
    "    # Visualize each test figure. \n",
    "    show_images([img_original])\n",
    "\n",
    "    # Print the actual class of each test figure. \n",
    "    print(\"Actual class :\", true_values[i], \" of file \", test_images[i])\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------------\n",
    "    # TODO 21: Calculate the prediction of each classifier (Minimum Distance, Nearest Neighbour, K-Nearest Neighbour)\n",
    "    knn_prediction.append(KNN(test_point, training_features, labels, k))\n",
    "    \n",
    "    print(\"knn_prediction class :\", knn_prediction[i])\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_predictions =  len(test_images)\n",
    "\n",
    "correct_knn=0\n",
    "for i in range(len(test_images)):\n",
    "    if(true_values[i]==knn_prediction[i]):\n",
    "        correct_knn=correct_knn+1\n",
    "\n",
    "accuracy_knn = (correct_knn/total_predictions)*100\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "\n",
    "print(\"K-Nearest Neighbour Classifier Accuracy: \", accuracy_knn, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
